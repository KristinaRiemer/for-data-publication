{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clemson Sorghum Experiments Data Cleaning Notebook\n",
    "#### Data from [Brenton et al., 2016](https://www.genetics.org/content/204/1/21) collected from Clemson University Pee Dee Research and Education Center in 2014\n",
    "- goal: to gather more cultivar and environmental data in addition to MAC Sorghum Seasons 4 & 6 and KSU Experiments\n",
    "- please contact Emily Cain at ejcain@arizona.edu with any questions or feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data queried from betydb in `R` using this code:\n",
    "```\n",
    "library(traits)\n",
    "\n",
    "options(betydb_url = \"https://terraref.ncsa.illinois.edu/bety/\",\n",
    "        betydb_api_version = 'v1',\n",
    "        betydb_key = 'secret_api_key_123456_abcde')\n",
    "        \n",
    "clemson <- betydb_query(experiment  = \"~Clemson\",\n",
    "                         limit     =  \"none\")\n",
    "                      \n",
    "write.csv(clemson, file = \"clemson_data_2020-06-01.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.read_csv('data/clemson_data_2020-06-01.csv')\n",
    "print(df_0.shape)\n",
    "# df_0.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_0.raw_date.min())\n",
    "# print(df_0.raw_date.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slice for selected traits\n",
    "- plant height\n",
    "- days & GDD to flowering\n",
    "- aboveground dry biomass\n",
    "- may use other traits as needed for future models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.trait.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_0.loc[(df_0.trait == 'flowering_time') | (df_0.trait == 'plant_height') | (df_0.trait == 'aboveground_dry_biomass')]\n",
    "print(df_1.shape)\n",
    "# df_1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop & Rename Columns\n",
    "- rename `mean` to `value`\n",
    "- convert `raw_date` to new datetime object\n",
    "- new datetime object will be in `date` column\n",
    "- drop `raw_date` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can drop most columns with only one value\n",
    "\n",
    "# for col in df_1.columns:\n",
    "    \n",
    "#     if df_1[col].nunique() < 5:\n",
    "#         print(f'Unique values for {col}: {df_1[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Unnamed: 0', 'checked', 'result_type', 'id', 'citation_id', 'site_id', 'treatment_id', \n",
    "                'commonname', 'genus', 'species_id', 'cultivar_id', 'month', 'year', 'dateloc', 'n', 'statname', \n",
    "                'stat', 'notes', 'access_level', 'entity', 'view_url', 'edit_url', 'date', 'time', 'method_name', \n",
    "                'treatment']\n",
    "\n",
    "df_2 = df_1.drop(labels=cols_to_drop, axis=1)\n",
    "print(df_2.shape)\n",
    "# df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert `raw_date` to datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dates = pd.to_datetime(df_2.raw_date)\n",
    "\n",
    "df_3 = df_2.copy()\n",
    "df_3['date'] = new_dates\n",
    "\n",
    "print(df_2.shape)\n",
    "print(df_3.shape)\n",
    "\n",
    "# df_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_3.rename({'mean': 'value'}, axis=1)\n",
    "print(df_4.shape)\n",
    "# df_4.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = df_4.drop(labels=['raw_date'], axis=1)\n",
    "print(df_5.shape)\n",
    "# df_5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Weather Data\n",
    "- downloaded from [NOAA](https://www.ncdc.noaa.gov/cdo-web/datasets#GHCND)\n",
    "- [Documentation](https://www1.ncdc.noaa.gov/pub/data/cdo/documentation/GHCND_documentation.pdf)\n",
    "- Florence Regional Airport Weather\n",
    "- will get temperatures first to calculate GDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_0 = pd.read_csv('data/clemson_weather_daily_2014.csv')\n",
    "print(weather_0.shape)\n",
    "# weather_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns with climate data other than temperature and precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['STATION', 'AWND', 'AWND_ATTRIBUTES', 'PGTM', 'PGTM_ATTRIBUTES', 'SNOW', 'SNOW_ATTRIBUTES', \n",
    "                'SNWD', 'SNWD_ATTRIBUTES', 'TSUN', 'TSUN_ATTRIBUTES', 'WDF2', 'WDF2_ATTRIBUTES', 'WDF5', \n",
    "                'WDF5_ATTRIBUTES', 'WSF2', 'WSF2_ATTRIBUTES', 'WSF5', 'WSF5_ATTRIBUTES', 'WT01', 'WT01_ATTRIBUTES', \n",
    "                'WT02', 'WT02_ATTRIBUTES', 'WT03', 'WT03_ATTRIBUTES', 'WT06', 'WT06_ATTRIBUTES', 'WT08', \n",
    "                'WT08_ATTRIBUTES', 'TAVG', 'TAVG_ATTRIBUTES', 'PRCP_ATTRIBUTES', 'TMAX_ATTRIBUTES', 'TMIN_ATTRIBUTES']\n",
    "\n",
    "weather_1 = weather_0.drop(labels=cols_to_drop, axis=1)\n",
    "print(weather_1.shape)\n",
    "# weather_1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename & Reorder Columns\n",
    "- add day of year\n",
    "- add cumulative precipitation\n",
    "- add average temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_of_year = list(range(1,366))\n",
    "cum_precip = list(np.cumsum(weather_1['PRCP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_precip_rounded = [round(p, 2) for p in cum_precip]\n",
    "# cum_precip_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_temps = weather_1[['TMIN', 'TMAX']].mean(axis=1)\n",
    "# avg_temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_temps_rounded = [round(t, 2) for t in avg_temps]\n",
    "# avg_temps_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_2 = pd.DataFrame(data={'date': weather_1['DATE'].values, 'day_of_year': days_of_year, \n",
    "                               'location': weather_1['NAME'].values, 'lat': weather_1['LATITUDE'].values, \n",
    "                               'lon': weather_1['LONGITUDE'].values, 'elevation_meters': weather_1['ELEVATION'].values, \n",
    "                               'temp_max': weather_1['TMAX'].values, 'temp_min': weather_1['TMIN'].values,\n",
    "                               'temp_avg': avg_temps_rounded, 'precip_mm': weather_1['PRCP'].values, \n",
    "                               'precip_cum': cum_precip_rounded})\n",
    "\n",
    "print(weather_2.shape)\n",
    "# weather_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Days & GDD to Flowering\n",
    "- planting date: 2014-05-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.trait.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_0 = df_5.loc[df_5.trait == 'flowering_time']\n",
    "print(fl_0.shape)\n",
    "# fl_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add planting date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_planting = datetime.date(2014,5,6)\n",
    "fl_1 = fl_0.copy()\n",
    "\n",
    "fl_1['date_of_planting'] = day_of_planting\n",
    "print(fl_1.shape)\n",
    "# fl_1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create timedelta using days to flowering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta_values = fl_1['value'].values\n",
    "dates_of_flowering = []\n",
    "\n",
    "for val in timedelta_values:\n",
    "    \n",
    "    date_of_flowering = day_of_planting + datetime.timedelta(days=val)\n",
    "    dates_of_flowering.append(date_of_flowering)\n",
    "    \n",
    "print(fl_1.shape[0])\n",
    "print(len(dates_of_flowering))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_2 = fl_1.copy()\n",
    "fl_2['date_of_flowering'] = dates_of_flowering\n",
    "print(fl_2.shape)\n",
    "# fl_2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge temperature data from weather dataframe with flowering dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = weather_2[['date', 'day_of_year', 'temp_max', 'temp_min']]\n",
    "print(temp_df.shape)\n",
    "# temp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add GDD to weather df for seasonal dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_1 = temp_df.loc[temp_df['date'] >= '2014-05-06']\n",
    "print(temp_df_1.shape)\n",
    "# temp_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_2 = temp_df_1.copy()\n",
    "temp_df_2['daily_gdd'] = (((temp_df_2['temp_max'] + temp_df_2['temp_min'])) / 2) - 10\n",
    "print(temp_df_2.shape)\n",
    "# temp_df_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for negative daily gdd values\n",
    "\n",
    "# temp_df_2.loc[temp_df_2.daily_gdd < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all negative values to 0\n",
    "\n",
    "temp_df_3 = temp_df_2.copy()\n",
    "\n",
    "for k,v in temp_df_2.iteritems():\n",
    "    \n",
    "    if k == 'daily_gdd':\n",
    "        v[v < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should return empty df now\n",
    "\n",
    "temp_df_3.loc[temp_df_2.daily_gdd < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to df with negative values\n",
    "\n",
    "# temp_df_3.loc[temp_df_2.daily_gdd == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_4 = temp_df_3.copy()\n",
    "temp_df_4['gdd'] = np.rint(np.cumsum(temp_df_4['daily_gdd']))\n",
    "print(temp_df_4.shape)\n",
    "# temp_df_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_5 = temp_df_4[['date', 'gdd']]\n",
    "print(temp_df_5.shape)\n",
    "# temp_df_5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert dates to datetime objects\n",
    "- date of flowering\n",
    "- date in the weather df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_3 = fl_2.copy()\n",
    "fl_3.date_of_flowering = pd.to_datetime(fl_3.date_of_flowering)\n",
    "# fl_3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_6 = temp_df_5.copy()\n",
    "temp_df_6.date = pd.to_datetime(temp_df_6.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_6.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_4 = fl_3.merge(temp_df_6, how='left', left_on='date_of_flowering', right_on='date')\n",
    "print(fl_4.shape)\n",
    "# fl_4.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename & Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['author', 'citation_year', 'trait', 'units', 'date_of_planting', 'date_x', 'date_y']\n",
    "\n",
    "fl_5 = fl_4.drop(labels=cols_to_drop, axis=1)\n",
    "print(fl_5.shape)\n",
    "# fl_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_6 = fl_5.rename({'value': 'days_to_flowering', 'gdd': 'gdd_to_flowering'}, axis=1)\n",
    "print(fl_6.shape)\n",
    "# fl_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fl_6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_order = ['sitename', 'city', 'lat', 'lon', 'scientificname', 'trait_description', 'cultivar', \n",
    "                 'days_to_flowering', 'gdd_to_flowering', 'date_of_flowering']\n",
    "\n",
    "fl_7 = pd.DataFrame(data=fl_6, columns=new_col_order)\n",
    "print(fl_7.shape)\n",
    "# fl_7.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write days to flowering df to `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "output_filename = f'data/processed/clemson_days_to_flowering_{timestamp}.csv'.replace(':', '')\n",
    "\n",
    "fl_7.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Plant Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_5.trait.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_0 = df_5.loc[df_5.trait == 'plant_height']\n",
    "print(ph_0.shape)\n",
    "# ph_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename, Drop, & Reorder Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_1 = ph_0.rename({'value': 'plant_height_cm'}, axis=1)\n",
    "# ph_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['author', 'citation_year', 'trait', 'units']\n",
    "\n",
    "ph_2 = ph_1.drop(labels=cols_to_drop, axis=1)\n",
    "print(ph_2.shape)\n",
    "# ph_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_order = ['sitename', 'city', 'lat', 'lon', 'scientificname', 'trait_description', 'cultivar', \n",
    "                'plant_height_cm', 'date']\n",
    "\n",
    "ph_3 = pd.DataFrame(data=ph_2, columns=new_col_order)\n",
    "print(ph_3.shape)\n",
    "# ph_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_4 = ph_3.set_index(keys=['date'])\n",
    "# ph_4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort index ascending\n",
    "\n",
    "ph_5 = ph_4.sort_index()\n",
    "print(ph_5.shape)\n",
    "ph_5.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write canopy heights to `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "output_filename = f'data/processed/clemson_canopy_heights_{timestamp}.csv'.replace(':', '')\n",
    "\n",
    "ph_5.to_csv(output_filename, index=True, index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Aboveground dry biomass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_0 = df_5.loc[df_5.trait == 'aboveground_dry_biomass']\n",
    "print(adb_0.shape)\n",
    "# adb_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename, Drop, & Reorder Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_1 = adb_0.rename({'value': 'aboveground_dry_biomass'}, axis=1)\n",
    "# adb_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['author', 'citation_year', 'trait', 'trait_description']\n",
    "\n",
    "adb_2 = adb_1.drop(labels=cols_to_drop, axis=1)\n",
    "print(adb_2.shape)\n",
    "# adb_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_order = ['date', 'sitename', 'city', 'lat', 'lon', 'scientificname', 'cultivar', \n",
    "                'aboveground_dry_biomass', 'units']\n",
    "\n",
    "adb_3 = pd.DataFrame(data=adb_2, columns=new_col_order)\n",
    "print(adb_3.shape)\n",
    "# adb_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_4 = adb_3.set_index(keys=['date'])\n",
    "adb_4.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write aboveground dry biomass df to `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "output_filename = f'data/processed/clemson_aboveground_dry_biomass_{timestamp}.csv'.replace(':', '')\n",
    "\n",
    "adb_4.to_csv(output_filename, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-data-cleaning",
   "language": "python",
   "name": "jupyter-data-cleaning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
