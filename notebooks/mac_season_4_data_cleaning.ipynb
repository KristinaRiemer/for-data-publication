{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC Season 4 Data Cleaning\n",
    "#### Traits\n",
    "- aboveground dry biomass\n",
    "- days & growing degree days (GDD) to flowering\n",
    "- days & GDD to flag leaf emergence\n",
    "- canopy height (time series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update July 2020\n",
    "##### The input data for the code in this notebook were downloaded from a Dryad data publication from the TERRA-REF project, lead author [David LeBauer](https://github.com/dlebauer). Information on the publication and access to data can be found in this [repository](https://github.com/terraref/data-publication). \n",
    "\n",
    "\n",
    "##### This notebook contains the code used to clean and curate sorghum data from Maricopa Agricultural Station Season Four. The input trait data were originally queried from betydb version 1 in April 2020 using this `R` code, but those data are no longer used in this notebook or for the updated derived datasets. \n",
    "\n",
    "```\n",
    "library(traits)\n",
    "library(dplyr)\n",
    "\n",
    "\n",
    "options(betydb_url = \"https://terraref.ncsa.illinois.edu/bety/\",\n",
    "        betydb_api_version = 'v1',\n",
    "        betydb_key = 'abcde_super_secret_key_1234')\n",
    "\n",
    "season_4 <- betydb_query(sitename  = \"~Season 4\",\n",
    "                         limit     =  \"none\")\n",
    "\n",
    "write.csv(season_4, file = 'mac_season_four_2020-04-22.csv')\n",
    "```\n",
    "- Environmental weather data were downloaded from the MAC weather station [website](https://cals.arizona.edu/azmet/06.htm). \n",
    "- Please email ejcain@arizona.edu with any questions or comments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Import Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import sqlalchemy \n",
    "# import sqlite3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Functions Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(df, value_column, trait_column):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return an exploratory histogram to visualize distribution of values of specific trait.\n",
    "    \"\"\"\n",
    "    trait_name = df[trait_column].unique()[0]\n",
    "    return df[value_column].hist(color='navy').set_xlabel(trait_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_nulls(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes dataframe as argument and returns table showing sum of null values, if any.\n",
    "    \"\"\"\n",
    "    \n",
    "    return df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes dataframe as argument and returns value counts for duplicates, if any.\n",
    "    \"\"\"\n",
    "    \n",
    "    return df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique_values(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function takes a dataframe as argument and checks for number of unique values in each column.\n",
    "    Print statement will contain number of unique values, as well as the unique values for any column that\n",
    "    contains less than 5 unique values.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        \n",
    "        if df[col].nunique() < 5:\n",
    "            print(f'{df[col].nunique()} unique value(s) for {col} column: {df[col].unique()}')\n",
    "            \n",
    "        else:\n",
    "            print(f'{df[col].nunique()} values for {col} column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_range_column_values(working_df, plot_column):\n",
    "    \n",
    "    \"\"\"\n",
    "    To assist in plot location, function takes the working dataframe name, name of the plot column, and\n",
    "    desired name of the new dataframe to be returned. Range and column values are extracted from the\n",
    "    plot name strings and added as new columns to the returned dataframe. \n",
    "    \"\"\"\n",
    "    \n",
    "    new_df = working_df.copy()\n",
    "\n",
    "    new_df['range'] = new_df[plot_column].str.extract(\"Range (\\d+)\").astype(int)\n",
    "    new_df['column'] = new_df[plot_column].str.extract(\"Column (\\d+)\").astype(int)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime_column(working_df, date_column):\n",
    "    \n",
    "    \"\"\"\n",
    "    If date column does not contain datetime objects, function takes working dataframe and name of date column\n",
    "    as arguments. The original date column is dropped, and a new dataframe with an updated datatime column\n",
    "    is returned. \n",
    "    \"\"\"\n",
    "    \n",
    "    new_datetimes = pd.to_datetime(working_df[date_column])\n",
    "    \n",
    "    new_df_0 = working_df.drop(labels=date_column, axis=1)\n",
    "    new_df_1 = new_df_0.copy()\n",
    "    new_df_1['date'] = new_datetimes\n",
    "    \n",
    "    return new_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_value_column(working_df, value_column, trait_column):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes working dataframe, name of value column, and name of trait column as arguments. Returns a new dataframe\n",
    "    with the name of the trait as the new name of the value column.\n",
    "    \"\"\"\n",
    "    \n",
    "    trait = working_df[trait_column].unique()[0]\n",
    "    \n",
    "    new_df_0 = working_df.rename({value_column: trait}, axis=1)\n",
    "    new_df_1 = new_df_0.drop(labels=trait_column, axis=1)\n",
    "    \n",
    "    return new_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may no longer need this function with new data\n",
    "# def check_for_subplots(df):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Function takes a dataframe as argument and checks for sitename subplots ending in ' E' or ' W'\n",
    "#     Will return rows with subplots, if any.\n",
    "#     \"\"\"\n",
    "#     return df.loc[(df.sitename.str.endswith(' E')) | (df.sitename.str.endswith(' W'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Read in datasets\n",
    "- Season Four data can be downloaded from this Google [Drive](https://drive.google.com/open?id=1THk-NQYxkkej-zdQsqM7i9t-axyS0Sug)\n",
    "- Each trait - separated by method, if applicable - can be found in its own `.csv` file\n",
    "- Functions applied to all datasets\n",
    "    - Plot distribution of values\n",
    "    - Check for null values\n",
    "    - Check for duplicates\n",
    "    - Extract range and column values to add to dataframe\n",
    "    - Convert string date column values to datetime objects\n",
    "    - Rename values column (usually 'mean') to the trait being measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Aboveground Dry Biomass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(719, 12)\n"
     ]
    }
   ],
   "source": [
    "adb_0 = pd.read_csv('data/raw/season_4_traits/season_4_aboveground_dry_biomass_manual.csv')\n",
    "print(adb_0.shape)\n",
    "# adb_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'aboveground_dry_biomass')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(adb_0, 'mean', 'trait')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot              0\n",
       "scientificname    0\n",
       "genotype          0\n",
       "treatment         0\n",
       "date              0\n",
       "trait             0\n",
       "method            0\n",
       "mean              0\n",
       "checked           0\n",
       "author            0\n",
       "season            0\n",
       "method_type       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_for_nulls(adb_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    719\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_duplicates(adb_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_unique_values(adb_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_1 = extract_range_column_values(adb_0, 'plot')\n",
    "print(adb_1.shape)\n",
    "# adb_1.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adb_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_2 = convert_datetime_column(adb_1, 'date')\n",
    "print(adb_2.shape)\n",
    "# adb_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adb_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_3 = rename_value_column(adb_2, 'mean', 'trait')\n",
    "print(adb_3.shape)\n",
    "# adb_3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original code to be refactored with more functions and different input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.read_csv('data/raw/mac_season_four_2020-04-22.csv', low_memory=False)\n",
    "print(df_0.shape)\n",
    "# df_0.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_0.columns:\n",
    "#     if df_0[col].nunique() < 5:\n",
    "#         print(f'Unique values for {col}: {df_0[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Unnamed: 0', 'checked', 'result_type', 'id', 'citation_id', 'site_id', 'treatment_id', 'city', \n",
    "                'scientificname', 'commonname', 'genus', 'species_id', 'author', 'citation_year', 'time', 'raw_date', \n",
    "                'month', 'year', 'dateloc', 'n', 'statname', 'stat', 'notes', 'access_level', 'entity', 'view_url', \n",
    "                'edit_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_0.drop(labels=cols_to_drop, axis=1)\n",
    "print(df_1.shape)\n",
    "# df_1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV. Change `date` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dates = []\n",
    "\n",
    "for d in df_1.date.values:\n",
    "    \n",
    "    # strip '(America/Phoenix)' string from date\n",
    "    if 'Phoenix' in d:\n",
    "        new_name = d[:-18]\n",
    "        new_dates.append(new_name)\n",
    "    \n",
    "    else:\n",
    "        new_name = d\n",
    "        new_dates.append(new_name)\n",
    "        \n",
    "\n",
    "# check that length of new dates matches number of rows\n",
    "print(len(new_dates))\n",
    "print(df_1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert string dates to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_format_dates = pd.to_datetime(new_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new column with datetime values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy df to avoid SettingWithCopyWarning\n",
    "df_2 = df_1.copy()\n",
    "df_2['date_1'] = iso_format_dates\n",
    "\n",
    "print(df_2.shape)\n",
    "# df_2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V. Extract Range & Column Values for Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_2.copy()\n",
    "\n",
    "df_3['range'] = df_3['sitename'].str.extract(\"Range (\\d+)\").astype(int)\n",
    "df_3['column'] = df_3['sitename'].str.extract(\"Column (\\d+)\").astype(int)\n",
    "\n",
    "# df_3.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VI. Drop, Rename, & Reorder Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop string date column and redundant trait columns\n",
    "\n",
    "df_4 = df_3.drop(labels=['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = df_4.rename({'date_1': 'date', 'mean': 'value'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_order = ['sitename', 'range', 'column', 'lat', 'lon', 'date', 'treatment', 'trait', 'trait_description', 'method_name', 'cultivar', 'value', 'units']\n",
    "\n",
    "df_6 = pd.DataFrame(data=df_5, columns=new_col_order).reset_index(drop=True)\n",
    "print(df_6.shape)\n",
    "# df_6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VI. Select for specific traits\n",
    "- aboveground dry biomass\n",
    "- days & GDD to flowering\n",
    "- days & GDD to flag leaf emergence\n",
    "- canopy height - time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Aboveground Dry Biomass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_0 = df_6.loc[df_6.trait == 'aboveground_dry_biomass']\n",
    "print(adb_0.shape)\n",
    "adb_0.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for E and W subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will have no output if there are no subplots\n",
    "\n",
    "check_for_subplots(adb_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop & Rename Columns, Set Date as Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['trait', 'trait_description', 'method_name']\n",
    "\n",
    "adb_1 = adb_0.drop(labels=cols_to_drop, axis=1)\n",
    "print(adb_1.shape)\n",
    "# adb_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_2 = adb_1.rename({'value': 'aboveground_dry_biomass'}, axis=1)\n",
    "# adb_2.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_3 = adb_2.set_index(keys='date')\n",
    "print(adb_3.shape)\n",
    "# adb_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_4 = adb_3.sort_index()\n",
    "adb_4.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write aboveground dry biomass dataframe to csv file with timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "output_filename = f'data/processed/aboveground_dry_biomass_mac_season_4_{timestamp}.csv'.replace(':', '')\n",
    "\n",
    "adb_4.to_csv(output_filename, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Days & Growing Degree Days (GDD) to Flowering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_df_0 = df_6.loc[df_6.trait == 'flowering_time']\n",
    "print(flower_df_0.shape)\n",
    "flower_df_0.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for E and W subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will have no output if there are no subplots\n",
    "\n",
    "check_for_subplots(flower_df_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in Season Four Weather Data from MAC Weather Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_0 = pd.read_csv('data/raw/mac_weather_station_raw_daily_2017.csv')\n",
    "print(weather_df_0.shape)\n",
    "weather_df_0.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slice dataframe for season dates only and add date column\n",
    "* Planting Date: 2017-04-20, Day 110\n",
    "* Last Day of Harvest: 2017-09-16, Day 259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_1 = weather_df_0.loc[(weather_df_0.day_of_year >= 110) & (weather_df_0.day_of_year <= 259)]\n",
    "print(weather_df_1.shape)\n",
    "weather_df_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_4_date_range = pd.date_range(start='2017-04-20', end='2017-09-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_2 = weather_df_1.copy()\n",
    "weather_df_2['date'] = season_4_date_range\n",
    "print(weather_df_2.shape)\n",
    "weather_df_2.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Growing Degree Days\n",
    "- 10 degrees Celsius is base temp for sorghum\n",
    "- Daily gdd value = ((max temp + min temp) / 2) - 10 (base temp)\n",
    "- Growing Degree Days = cumulative sum of daily gdd values\n",
    "- Negative values convert to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_3 = weather_df_2.copy()\n",
    "weather_df_3['daily_gdd'] = (((weather_df_3['air_temp_max'] + weather_df_3['air_temp_min'])) / 2) - 10\n",
    "print(weather_df_3.shape)\n",
    "weather_df_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for negative values - will return empty df if there are none\n",
    "\n",
    "weather_df_3.loc[weather_df_3.daily_gdd < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_4 = weather_df_3.copy()\n",
    "weather_df_4['gdd'] = np.rint(np.cumsum(weather_df_4['daily_gdd']))\n",
    "print(weather_df_4.shape)\n",
    "weather_df_4.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop daily gdd\n",
    "\n",
    "weather_df_5 = weather_df_4.drop(labels='daily_gdd', axis=1)\n",
    "print(weather_df_5.shape)\n",
    "# weather_df_5.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_6 = weather_df_5.copy()\n",
    "weather_df_6['cum_precip'] = np.round(np.cumsum(weather_df_6.precip_total), 2)\n",
    "weather_df_6.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Irrigation Columns\n",
    "- First water-deficit stress treatment: 2020-08-01 through 2020-08-14\n",
    "- Second water-deficit stress treatment: 2020-08-15 through 2020-08-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_df_6.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_treatment_dates = pd.date_range(start='2017-08-01', end='2017-08-14')\n",
    "second_treatment_dates = pd.date_range(start='2017-08-15', end='2017-08-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_dates = weather_df_6.date.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_treatment_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a date falls within a treatment date range, it will have a value of True in the water deficit columns\n",
    "\n",
    "first_treatment_col = []\n",
    "\n",
    "\n",
    "for d in season_dates:\n",
    "    \n",
    "    if d in first_treatment_dates:\n",
    "        \n",
    "        first_treatment_col.append(True)\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        first_treatment_col.append(False)\n",
    "        \n",
    "print(len(first_treatment_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_treatment_col = []\n",
    "\n",
    "for d in season_dates:\n",
    "    \n",
    "    if d in second_treatment_dates:\n",
    "        \n",
    "        second_treatment_col.append(True)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        second_treatment_col.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_7 = weather_df_6.copy()\n",
    "\n",
    "weather_df_7['first_water_deficit_treatment'] = first_treatment_col\n",
    "weather_df_7['second_water_deficit_treatment'] = second_treatment_col\n",
    "\n",
    "print(weather_df_7.shape)\n",
    "weather_df_7.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write weather data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "output_filename = f'data/processed/mac_season_4_daily_weather_{timestamp}.csv'.replace(':', '')\n",
    "\n",
    "weather_df_7.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add planting date 2017-04-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_planting = datetime.date(2017,4,20)\n",
    "flower_df_1 = flower_df_0.copy()\n",
    "\n",
    "flower_df_1['date_of_planting'] = day_of_planting\n",
    "print(flower_df_1.shape)\n",
    "# flower_df_1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create timedelta using days to flowering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta_values = flower_df_1['value'].values\n",
    "dates_of_flowering = []\n",
    "\n",
    "for val in timedelta_values:\n",
    "    \n",
    "    date_of_flowering = day_of_planting + datetime.timedelta(days=val)\n",
    "    dates_of_flowering.append(date_of_flowering)\n",
    "    \n",
    "print(flower_df_1.shape[0])\n",
    "print(len(dates_of_flowering))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_df_2 = flower_df_1.copy()\n",
    "flower_df_2['date_of_flowering'] = dates_of_flowering\n",
    "print(flower_df_2.shape)\n",
    "# flower_df_2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add GDD to flowering dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice df for date and cumulative gdd values only\n",
    "\n",
    "season_4_gdd = weather_df_6[['date', 'gdd']]\n",
    "print(season_4_gdd.shape)\n",
    "season_4_gdd.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flower_df_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_df_3 = flower_df_2.copy()\n",
    "flower_df_3.date_of_flowering = pd.to_datetime(flower_df_3.date_of_flowering)\n",
    "# flower_df_3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_df_4 = flower_df_3.merge(season_4_gdd, how='left', left_on='date_of_flowering', right_on='date')\n",
    "print(flower_df_4.shape)\n",
    "# flower_df_4.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop, Rename, and Sort Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['date_x', 'trait', 'method_name', 'units', 'date_of_planting', 'date_y']\n",
    "flower_df_5 = flower_df_4.drop(labels=cols_to_drop, axis=1)\n",
    "print(flower_df_5.shape)\n",
    "# flower_df_5.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_df_6 = flower_df_5.rename({'value': 'days_to_flowering', 'gdd': 'gdd_to_flowering'}, axis=1)\n",
    "print(flower_df_6.shape)\n",
    "# flower_df_6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_df_6.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = flower_df_6.loc[flower_df_6.duplicated() == True]\n",
    "duplicates.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicates.loc[(duplicates.sitename == 'MAC Field Scanner Season 4 Range 46 Column 6') & (duplicates.cultivar == 'PI542718')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_df_7 = flower_df_6.drop_duplicates(ignore_index=True)\n",
    "print(flower_df_7.shape)\n",
    "flower_df_7.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of non-duplicates in flower_df_6: {flower_df_6.loc[flower_df_6.duplicated() == False].shape[0]}')\n",
    "print(f'Number of rows in dataframe after dropping duplicates: {flower_df_7.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write days to flowering dataframe to csv file with timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "output_filename = f'data/processed/days_gdd_to_flowering_season_4_{timestamp}.csv'.replace(':', '')\n",
    "\n",
    "flower_df_7.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Days & GDD to Flag Leaf Emergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_0 = df_6.loc[df_6.trait == 'flag_leaf_emergence_time']\n",
    "print(fle_0.shape)\n",
    "# fle_0.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for E and W subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will have no output if there are no subplots\n",
    "\n",
    "check_for_subplots(fle_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use sliced dataframe from days to flowering with date and gdd values only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_4_gdd.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add planting date 2017-04-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_planting = datetime.date(2017,4,20)\n",
    "fle_1 = fle_0.copy()\n",
    "\n",
    "fle_1['date_of_planting'] = day_of_planting\n",
    "print(fle_1.shape)\n",
    "# fle_1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create timedelta using days to flag leaf emergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta_values = fle_1['value'].values\n",
    "dates_of_flag_leaf_emergence = []\n",
    "\n",
    "for val in timedelta_values:\n",
    "    \n",
    "    date_of_flag_leaf_emergence = day_of_planting + datetime.timedelta(days=val)\n",
    "    dates_of_flag_leaf_emergence.append(date_of_flag_leaf_emergence)\n",
    "    \n",
    "print(fle_1.shape[0])\n",
    "print(len(dates_of_flag_leaf_emergence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_2 = fle_1.copy()\n",
    "fle_2['date_of_flag_leaf_emergence'] = dates_of_flag_leaf_emergence\n",
    "print(fle_2.shape)\n",
    "# fle_2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add GDD to flag leaf emergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fle_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_3 = fle_2.copy()\n",
    "fle_3.date_of_flag_leaf_emergence = pd.to_datetime(fle_3.date_of_flag_leaf_emergence)\n",
    "# fle_3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_4 = fle_3.merge(season_4_gdd, how='left', left_on='date_of_flag_leaf_emergence', right_on='date')\n",
    "print(fle_4.shape)\n",
    "# fle_4.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop & Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['date_x', 'trait', 'method_name', 'units', 'date_of_planting', 'date_y']\n",
    "fle_5 = fle_4.drop(labels=cols_to_drop, axis=1)\n",
    "print(fle_5.shape)\n",
    "# fle_5.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_6 = fle_5.rename({'value': 'days_to_flag_leaf_emergence', 'gdd': 'gdd_to_flag_leaf_emergence'}, axis=1)\n",
    "print(fle_6.shape)\n",
    "# fle_6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_6.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fle_6.loc[fle_6.duplicated() == True].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fle_6.loc[(fle_6.sitename == 'MAC Field Scanner Season 4 Range 16 Column 7') & (fle_6.cultivar == 'PI152651')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_7 = fle_6.drop_duplicates(ignore_index=True)\n",
    "print(fle_7.shape)\n",
    "fle_7.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write days to flag leaf emergence to csv file with timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "output_filename = f'data/processed/days_gdd_to_flag_leaf_emergence_season_4_{timestamp}.csv'.replace(':', '')\n",
    "\n",
    "fle_7.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Canopy Height - Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_0 = df_6.loc[df_6.trait == 'canopy_height']\n",
    "print(ch_0.shape)\n",
    "# ch_0.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots = check_for_subplots(ch_0)\n",
    "subplots.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take average canopy height values for subplots on same day\n",
    "- Strip ` E` and ` W` subplot designations\n",
    "- Group by rows with the same sitename and date and take the average value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitename_values = ch_0.sitename.values\n",
    "no_e_w_names = []\n",
    "\n",
    "for name in sitename_values:\n",
    "    \n",
    "    if name.endswith(' W') | name.endswith(' E'):\n",
    "        name = name[:-2]\n",
    "        no_e_w_names.append(name)\n",
    "        \n",
    "    else:\n",
    "        no_e_w_names.append(name)\n",
    "        \n",
    "print(len(no_e_w_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add new sitename column with no subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_1 = ch_0.copy()\n",
    "ch_1['sitename_1'] = no_e_w_names\n",
    "print(ch_1.shape)\n",
    "# ch_1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use sqlite database to group by `sitename_1` and `date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('canopy_heights_season_4.sqlite')\n",
    "cursor = conn.cursor()\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment next line out if db has already been created\n",
    "ch_1.to_sql('canopy_heights_season_4.sqlite', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_2 = pd.read_sql_query(\"\"\"\n",
    "                            SELECT sitename_1 AS sitename, range, column, lat, lon, date, treatment, \n",
    "                            trait, trait_description, method_name, cultivar, \n",
    "                            ROUND(AVG(value), 2) AS avg_canopy_height, units \n",
    "                            FROM 'canopy_heights_season_4.sqlite'\n",
    "                            GROUP BY sitename_1, date, cultivar\n",
    "                            ORDER BY date ASC;\n",
    "                            \"\"\", conn)\n",
    "\n",
    "print(ch_2.shape)\n",
    "# ch_2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "\n",
    "sample_with_subplot = ch_1.loc[(ch_1.range == 5) & (ch_1.column == 7) & (ch_1.date == '2017-07-11')]\n",
    "sample_with_subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check - should have only one row for the above group\n",
    "\n",
    "sample_without_subplot = ch_2.loc[(ch_2.range == 5) & (ch_2.column == 7) & (ch_2.date == '2017-07-11 00:00:00')]\n",
    "sample_without_subplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop, Rename, and Reorder Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['trait', 'trait_description', 'units']\n",
    "\n",
    "ch_3 = ch_2.drop(labels=cols_to_drop, axis=1)\n",
    "print(ch_3.shape)\n",
    "# ch_3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_4 = ch_3.rename({'avg_canopy_height': 'canopy_height_cm'}, axis=1)\n",
    "# ch_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_5 = ch_4.set_index(keys='date').sort_index()\n",
    "print(ch_5.shape)\n",
    "ch_5.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write canopy height dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "output_filename = f'data/processed/canopy_heights_season_4_{timestamp}.csv'.replace(':', '')\n",
    "\n",
    "ch_5.to_csv(output_filename, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
